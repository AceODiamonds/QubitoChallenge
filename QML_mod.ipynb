{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1uGasVd0WlA",
        "outputId": "2d44dce9-8e58-456e-f1ea-431507aeb89b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.10/dist-packages (0.39.0)\n",
            "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.4.2)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.15.1)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.7.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n",
            "Requirement already satisfied: pennylane-lightning>=0.39 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.39.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJAQl6LT0Q-5"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import math\n",
        "from typing import Any\n",
        "\n",
        "import pennylane as qml\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "#device_gpu = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class VQC(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_wires: int,\n",
        "        num_outputs: int,\n",
        "        num_layers: int,\n",
        "        encoding: str = \"angle\",\n",
        "        reuploading: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        \"\"\"\n",
        "        Constructor\n",
        "        @encoding: String which represents the gates used for the Angle encoding\n",
        "        @Ansatz: String which represents the ansatz used for quantum circuit\n",
        "        @Reuploading: Boolean indicating whether or not to use reuploading\n",
        "        @hadamard: Boolean indicating whether or not to use Hadamard gates\n",
        "        @num_layers: Integer representing the number of layers in the quantum circuit\n",
        "        @num_wires: Integer representing the number of wires in the quantum circuit\n",
        "        @num_outputs: Integer representing the number of output qubits\n",
        "        @gate_used: String representing the encoding gate used\n",
        "        @name_ansatz: String representing the ansatz used\n",
        "        \"\"\"\n",
        "        self.encoding = encoding\n",
        "        self.reuploading = reuploading\n",
        "        self.num_layers = num_layers\n",
        "        self.num_wires = num_wires\n",
        "        self.num_outputs = num_outputs\n",
        "\n",
        "        # PennyLane device\n",
        "        self.dev = qml.device(\"default.qubit\", wires=self.num_wires)\n",
        "\n",
        "\n",
        "        # Set device for PyTorch\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.weight_shapes = {\"weights\": (self.num_layers, self.num_wires, 3)}\n",
        "        # Create the quantum node\n",
        "        self.qnode = self.create_qnode()\n",
        "        # Define the quantum layer in PyTorch\n",
        "        self.qlayer = qml.qnn.TorchLayer(self.qnode, self.weight_shapes).to(self.device)\n",
        "\n",
        "    def create_qnode(self) -> qml.QNode:\n",
        "        \"\"\"Creates the quantum node for the hybrid model.\"\"\"\n",
        "\n",
        "        @qml.qnode(self.dev)\n",
        "        def qnode(inputs: torch.Tensor, weights: torch.nn.parameter.Parameter) -> list[Any]:\n",
        "            # Encoding and Ansatz logic\n",
        "            if self.reuploading:\n",
        "                if self.encoding == \"angle\":\n",
        "                    for w in weights:\n",
        "                        self.encoding_circuit(inputs)\n",
        "                        self.apply_ansatz(w.unsqueeze(0))\n",
        "                elif self.encoding == \"amplitude\":\n",
        "                    msg = \"Amplitude encoding is not supported with re-uploading.\"\n",
        "                    raise ValueError(msg)\n",
        "            else:\n",
        "                self.encoding_circuit(inputs)\n",
        "                self.apply_ansatz(weights)\n",
        "\n",
        "            # Measurement\n",
        "            return [qml.expval(qml.PauliZ(wires=i)) for i in range(self.num_outputs)]\n",
        "\n",
        "        return qnode\n",
        "\n",
        "    def apply_ansatz(self, weights: torch.nn.parameter.Parameter) -> None:\n",
        "        qml.StronglyEntanglingLayers(weights, wires=range(self.num_wires))\n",
        "\n",
        "    def encoding_circuit(self, inputs: torch.Tensor) -> None:\n",
        "        \"\"\"\n",
        "        Apply encoding circuit based on the specified encoding method.\n",
        "        @ inputs: array of input values in range [-1, 1]\n",
        "        \"\"\"\n",
        "        if self.encoding == \"angle\":\n",
        "            qml.AngleEmbedding(math.pi / 2 * inputs, wires=range(self.num_wires), rotation='Y')\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward pass through the hybrid model.\"\"\"\n",
        "        return self.qlayer(inputs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('./Breast_Cancer.csv')"
      ],
      "metadata": {
        "id": "UTlZY0p-NZa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data transformation\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('./Breast_Cancer.csv')\n",
        "\n",
        "#'differentiate' and 'Grade'\n",
        "ordinal_mapping = {\n",
        "    \"differentiate\": {\n",
        "        \"Poorly differentiated\": 1,\n",
        "        \"Moderately differentiated\": 2,\n",
        "        \"Well differentiated\": 3\n",
        "    },\n",
        "    \"Grade\": {\n",
        "        \"1\": 1,\n",
        "        \"2\": 2,\n",
        "        \"3\": 3\n",
        "    }\n",
        "}\n",
        "\n",
        "for col, mapping in ordinal_mapping.items():\n",
        "    df[col] = df[col].map(mapping)\n",
        "\n",
        "# encoding for other categorical columns\n",
        "label_columns = [\n",
        "    \"Race\", \"Marital Status\", \"T Stage\", \"N Stage\", \"6th Stage\",\n",
        "    \"A Stage\", \"Estrogen Status\", \"Progesterone Status\", \"Status\"\n",
        "]\n",
        "\n",
        "label_encoders = {}\n",
        "for col in label_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "\n",
        "print(df.head(n=21))\n",
        "print(df.info())\n",
        "\n",
        "\n",
        "# print(df.loc[-1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLX8biJba_Dm",
        "outputId": "96c65466-fe4d-402f-f965-c22e61335e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Age  Race  Marital Status  T Stage  N Stage  6th Stage  differentiate  \\\n",
            "0    68     2               1        0        0          0            1.0   \n",
            "1    50     2               1        1        1          2            2.0   \n",
            "2    58     2               0        2        2          4            2.0   \n",
            "3    58     2               1        0        0          0            1.0   \n",
            "4    47     2               1        1        0          1            1.0   \n",
            "5    51     2               3        0        0          0            2.0   \n",
            "6    51     2               1        0        0          0            3.0   \n",
            "7    40     2               1        1        0          1            2.0   \n",
            "8    40     2               0        3        2          4            1.0   \n",
            "9    69     2               1        3        2          4            3.0   \n",
            "10   68     2               4        0        0          0            2.0   \n",
            "11   46     2               1        2        0          2            1.0   \n",
            "12   65     2               1        1        0          1            1.0   \n",
            "13   48     2               1        0        1          2            1.0   \n",
            "14   62     2               0        1        2          4            2.0   \n",
            "15   61     2               1        0        0          0            2.0   \n",
            "16   56     2               3        1        0          1            2.0   \n",
            "17   43     2               1        1        0          1            2.0   \n",
            "18   48     0               0        1        0          1            2.0   \n",
            "19   60     2               0        1        0          1            2.0   \n",
            "20   48     1               1        1        0          1            3.0   \n",
            "\n",
            "    Grade  A Stage  Tumor Size  Estrogen Status  Progesterone Status  \\\n",
            "0     3.0        1           4                1                    1   \n",
            "1     2.0        1          35                1                    1   \n",
            "2     2.0        1          63                1                    1   \n",
            "3     3.0        1          18                1                    1   \n",
            "4     3.0        1          41                1                    1   \n",
            "5     2.0        1          20                1                    1   \n",
            "6     1.0        1           8                1                    1   \n",
            "7     2.0        1          30                1                    1   \n",
            "8     3.0        1         103                1                    1   \n",
            "9     1.0        0          32                1                    1   \n",
            "10    2.0        1          13                1                    1   \n",
            "11    3.0        1          59                0                    0   \n",
            "12    3.0        1          35                1                    1   \n",
            "13    3.0        1          15                1                    1   \n",
            "14    2.0        1          35                1                    1   \n",
            "15    2.0        1          19                1                    1   \n",
            "16    2.0        1          46                1                    1   \n",
            "17    2.0        1          24                1                    1   \n",
            "18    2.0        1          25                1                    1   \n",
            "19    2.0        1          29                0                    0   \n",
            "20    1.0        1          30                1                    1   \n",
            "\n",
            "    Regional Node Examined  Reginol Node Positive  Survival Months  Status  \n",
            "0                       24                      1               60       0  \n",
            "1                       14                      5               62       0  \n",
            "2                       14                      7               75       0  \n",
            "3                        2                      1               84       0  \n",
            "4                        3                      1               50       0  \n",
            "5                       18                      2               89       0  \n",
            "6                       11                      1               54       0  \n",
            "7                        9                      1               14       1  \n",
            "8                       20                     18               70       0  \n",
            "9                       21                     12               92       0  \n",
            "10                       9                      1               64       1  \n",
            "11                      11                      3               92       0  \n",
            "12                      13                      3               56       0  \n",
            "13                      23                      7               38       0  \n",
            "14                      16                     14               64       0  \n",
            "15                      20                      1               49       0  \n",
            "16                       1                      1              105       0  \n",
            "17                      22                      1               62       0  \n",
            "18                      16                      1              107       0  \n",
            "19                      20                      1               77       0  \n",
            "20                      15                      2               81       0  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4024 entries, 0 to 4023\n",
            "Data columns (total 16 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   Age                     4024 non-null   int64  \n",
            " 1   Race                    4024 non-null   int64  \n",
            " 2   Marital Status          4024 non-null   int64  \n",
            " 3   T Stage                 4024 non-null   int64  \n",
            " 4   N Stage                 4024 non-null   int64  \n",
            " 5   6th Stage               4024 non-null   int64  \n",
            " 6   differentiate           4005 non-null   float64\n",
            " 7   Grade                   4005 non-null   float64\n",
            " 8   A Stage                 4024 non-null   int64  \n",
            " 9   Tumor Size              4024 non-null   int64  \n",
            " 10  Estrogen Status         4024 non-null   int64  \n",
            " 11  Progesterone Status     4024 non-null   int64  \n",
            " 12  Regional Node Examined  4024 non-null   int64  \n",
            " 13  Reginol Node Positive   4024 non-null   int64  \n",
            " 14  Survival Months         4024 non-null   int64  \n",
            " 15  Status                  4024 non-null   int64  \n",
            "dtypes: float64(2), int64(14)\n",
            "memory usage: 503.1 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the file just in case\n",
        "df.to_csv('./Transformed_Breast_Cancer.csv', index=False)\n",
        "\n",
        "print(\"Transformed DataFrame has been saved as 'Transformed_Breast_Cancer.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ossrHFglotzz",
        "outputId": "aee4d40f-d772-4997-b357-b2d05bc81dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed DataFrame has been saved as 'Transformed_Breast_Cancer.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xz2yL1tf0Q_A"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = df.drop('Status', axis=1)\n",
        "y = df['Status']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
        "# Initialize MinMaxScaler with a range of (-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "# Fit and transform the training data, then transform the test data\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "\n",
        "# Convert the arrays into PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "X_valid = torch.tensor(X_valid, dtype=torch.float32)\n",
        "y_valid = torch.tensor(y_valid.values, dtype=torch.float32).view(-1, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTHAfgW80Q_B"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "def evaluation(\n",
        "    model: nn.Module,\n",
        "    x: torch.Tensor,\n",
        "    y: torch.Tensor,\n",
        "    threshold_classification: float = 0.5\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Evaluate the model\n",
        "    @model: nn.Module, model to evaluate, MANDATORY\n",
        "    @x: torch.Tensor, data, MANDATORY\n",
        "    @y: torch.Tensor, labels, MANDATORY\n",
        "    @criterion: None|nn.Module, loss function\n",
        "    @threshold_classification: float, threshold for classification\n",
        "    @metrics: None|list[str], list of metrics to evaluate\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # function needed for VQC\n",
        "        y_pred = (1 - model(x)) / 2\n",
        "    print(classification_report(y, y_pred > threshold_classification))\n",
        "    print(confusion_matrix(y, y_pred > threshold_classification))\n",
        "\n",
        "import torch\n",
        "\n",
        "def train(\n",
        "    model: nn.Module,\n",
        "    x_train: torch.Tensor,\n",
        "    y_train: torch.Tensor,\n",
        "    x_valid: None | torch.Tensor = None,\n",
        "    y_valid: None | torch.Tensor = None,\n",
        "    optimizer: torch.optim.Optimizer = None,\n",
        "    criterion: None | nn.Module = None,\n",
        "    epochs: int = 100,\n",
        "    batch_size: int = 32,\n",
        "    lr = 0.01,\n",
        "    early_stopping: bool = True,\n",
        "    patience: int = 5,\n",
        "    threshold_classification: float = 0.5,\n",
        "    verbose: bool = True,\n",
        ") -> nn.Module:\n",
        "    # Initialize metrics and losses\n",
        "    if criterion is None:\n",
        "        criterion = nn.BCELoss() if model.num_outputs == 1 else nn.CrossEntropyLoss()\n",
        "    if optimizer is None:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    min_loss = float(\"inf\")\n",
        "    patience_counter = 0\n",
        "    best_model_state = model.state_dict()  # Track best model state\n",
        "\n",
        "    x_train_dataloader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        loss_res = 0\n",
        "        for x_batch, y_batch in x_train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = (1 - model(x_batch)) / 2\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_res += loss.item()\n",
        "        loss_res /= len(x_train_dataloader)\n",
        "\n",
        "        if early_stopping and x_valid is not None and y_valid is not None:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                y_pred_valid = (1 - model(x_valid)) / 2\n",
        "                loss_valid = criterion(y_pred_valid, y_valid)\n",
        "\n",
        "            if loss_valid < min_loss:\n",
        "                min_loss = loss_valid\n",
        "                patience_counter = 0\n",
        "                best_model_state = model.state_dict()  # Save best model state\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            # Early stopping condition\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
        "                model.load_state_dict(best_model_state)  # Restore best model\n",
        "                break\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch + 1}/{epochs} - loss: {loss_res:.4f}\")\n",
        "            print(\"Train\")\n",
        "            evaluation(\n",
        "                model=model,\n",
        "                x=x_train,\n",
        "                y=y_train,\n",
        "                threshold_classification=threshold_classification\n",
        "            )\n",
        "            if x_valid is not None and y_valid is not None:\n",
        "                print(\"Validation\")\n",
        "                evaluation(\n",
        "                    model=model,\n",
        "                    x=x_valid,\n",
        "                    y=y_valid,\n",
        "                    threshold_classification=threshold_classification\n",
        "                )\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyAaDcCV0Q_C",
        "outputId": "b95e613e-d42e-41af-ce4d-496bc1b955a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'VQC' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6da711c28815>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVQC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_wires\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"angle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuploading\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'VQC' is not defined"
          ]
        }
      ],
      "source": [
        "model = VQC(num_wires=15, num_outputs=1, num_layers=16, encoding=\"angle\", reuploading=False)\n",
        "model = train(model, X_train, y_train,X_valid, y_valid, epochs=100, lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Acbvr9-I0Q_E",
        "outputId": "8727f79a-67e5-494b-ebc6-ce28c28874df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.93      0.84       321\n",
            "         1.0       0.76      0.45      0.57       170\n",
            "\n",
            "    accuracy                           0.76       491\n",
            "   macro avg       0.76      0.69      0.70       491\n",
            "weighted avg       0.76      0.76      0.74       491\n",
            "\n",
            "[[297  24]\n",
            " [ 93  77]]\n"
          ]
        }
      ],
      "source": [
        "evaluation(model, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnrK4zyf0Q_E",
        "outputId": "9d1ca43d-1b34-45bd-9a6a-2fa7f7697111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.78      0.91      0.84        80\n",
            "         1.0       0.76      0.51      0.61        43\n",
            "\n",
            "    accuracy                           0.77       123\n",
            "   macro avg       0.77      0.71      0.73       123\n",
            "weighted avg       0.77      0.77      0.76       123\n",
            "\n",
            "[[73  7]\n",
            " [21 22]]\n"
          ]
        }
      ],
      "source": [
        "evaluation(model, X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLt3QpPI0Q_F",
        "outputId": "9f67aa4b-8e90-40d8-f427-b47b47fa4661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.85      0.80        99\n",
            "         1.0       0.66      0.53      0.59        55\n",
            "\n",
            "    accuracy                           0.73       154\n",
            "   macro avg       0.71      0.69      0.69       154\n",
            "weighted avg       0.73      0.73      0.73       154\n",
            "\n",
            "[[84 15]\n",
            " [26 29]]\n"
          ]
        }
      ],
      "source": [
        "evaluation(model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJZY7Rf-0Q_F"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "QML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}